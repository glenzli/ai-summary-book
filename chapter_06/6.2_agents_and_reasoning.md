# 6.2 智能体与推理：从被动回答到主动行动 (Agents & Reasoning: From Passive QA to Active Action)

## 1. 语言模型的局限 (The Limitations of LLMs)

虽然 LLM 知识渊博，但它们本质上是 **被动** 的、 **静态** 的。
1.  **无法访问外部世界**: 它们不知道现在的准确时间，也不知道今天的天气。
2.  **数学与逻辑缺陷**: 纯粹的“预测下一个词”在处理复杂数学运算时经常出错（3.9 和 3.11 哪个大？）。
3.  **缺乏行动力**: 它们只能输出文本，不能帮你发邮件或订票。

**智能体 (Agent)** 技术旨在赋予 LLM **工具 (Tools)** 和 **推理过程 (Reasoning Process)**。

## 2. 思维链 (Chain of Thought, CoT)

在让模型行动之前，首先要让它学会“思考”。
Google 提出的 **思维链 (Chain of Thought, CoT)** 是一项革命性的发现：只要在 Prompt 中加入一句 *"Let's think step by step"*，或者提供包含推理步骤的示例，模型的逻辑能力就会大幅提升。

### 2.1 范式对比 (Paradigm Comparison)

```mermaid
graph TD
    %% 样式定义
    classDef standard fill:#F5F5F5,stroke:#666666,color:#000000;
    classDef cot fill:#DAE8FC,stroke:#6C8EBF,color:#000000;

    subgraph Standard [标准提示 (Standard Prompting)]
        Q1("Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 balls. How many balls does he have now?"):::standard
        A1("A: The answer is 11."):::standard
        Q1 --> A1
    end

    subgraph CoT [思维链提示 (Chain of Thought)]
        Q2("Q: Roger has 5 tennis balls..."):::cot
        R2("Reasoning: Roger started with 5 balls.\n2 cans of 3 balls each is 6 balls.\n5 + 6 = 11."):::cot
        A2("A: The answer is 11."):::cot
        Q2 --> R2 --> A2
    end
```

<span style="background-color: #FFF2CC; color: black; padding: 2px 4px; border-radius: 4px;">原理</span>：CoT 将一个复杂的 \( P(y|x) \) 问题分解成了多个简单的 \( P(z_t | x, z_{<t}) \) 步骤，实际上是增加了计算深度（Test-time Compute）。

## 3. ReAct: 推理与行动 (Reasoning + Acting)

有了推理能力，我们就可以引入工具使用 (Tool Use)。
**推理-行动 (ReAct, Reasoning + Acting)** 框架让模型在“思考”和“行动”之间循环。

### 3.1 ReAct 循环 (The Loop)
1.  **Thought (思考)**: 我需要做什么？现在缺什么信息？
2.  **Action (行动)**: 调用搜索引擎、计算器或 Python 解释器。
3.  **Observation (观察)**: 获取工具返回的结果。
4.  **Repeat**: 根据观察结果进行下一轮思考，直到解决问题。

```text
Question: What is the elevation range of the area that the eastern sector of the Colorado orogeny extends into?

Thought 1: I need to search for "Colorado orogeny" and find the area its eastern sector extends into.
Action 1: Search["Colorado orogeny"]
Observation 1: The Colorado orogeny was an episode of mountain building... extends into the High Plains.

Thought 2: The eastern sector extends into the High Plains. I need to find the elevation range of the High Plains.
Action 2: Search["High Plains elevation"]
Observation 2: The High Plains has an elevation of 2,500 to 6,000 feet (760 to 1,830 m).

Thought 3: I have the answer.
Answer: 2,500 to 6,000 feet.
```

## 4. 智能体架构 (Agent Architecture)

一个现代 AI Agent 通常包含三个核心组件：
1.  **大脑 (Brain)**: LLM (如 GPT-4)，负责规划与决策。
2.  **记忆 (Memory)**:
    *   短期记忆：上下文窗口。
    *   长期记忆：向量数据库 (Vector DB)。
3.  **工具 (Tools)**: 代码解释器、浏览器、API 接口。

```mermaid
graph LR
    %% 样式定义
    classDef brain fill:#DAE8FC,stroke:#6C8EBF,color:#000000;
    classDef tool fill:#FFF2CC,stroke:#D6B656,color:#000000;
    classDef mem fill:#E1D5E7,stroke:#9673A6,color:#000000;
    classDef env fill:#F5F5F5,stroke:#666666,color:#000000;

    User[User Goal]:::env --> Planner{Planner / LLM}:::brain

    Planner -->|Plan| Tool[Tools]:::tool
    Tool -->|Observation| Planner

    Planner -->|Write| STM[Short-term Memory\n(Context)]:::mem
    STM -->|Recall| Planner

    Planner -->|Retrieve| LTM[Long-term Memory\n(Vector DB)]:::mem
    LTM -->|Documents| Planner

    Planner --> Action[Final Action / Answer]:::env
```

## 5. 总结 (Summary)

Agent 技术正在将 LLM 从“百科全书”转变为“全能管家”。
未来的软件开发范式可能会从“人写代码控制机器”转变为“人提出目标，Agent 编写并执行代码来达成目标”。
